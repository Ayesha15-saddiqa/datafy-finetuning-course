{"cells":[{"cell_type":"code","source":["# Install python packages\n","! pip install lamini\n","! pip install python-dotenv\n","! pip install jsonlines\n","! pip install datasets\n","! pip install transformers"],"metadata":{"id":"VK9VAb_uWF5Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Assuming, you have cloned the Repo in first step"],"metadata":{"id":"E6MTNqsIWLWJ"}},{"cell_type":"code","source":["# Mount the Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# clone if not done before\n","# !git clone https://github.com/amjadraza/datafy-finetuning-course.git /content/drive/MyDrive/datafy-finetuning-course\n","\n","%cd drive/MyDrive/datafy-finetuning-course"],"metadata":{"id":"84EQ_zIiWNs4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKn-Y_Pk9WjC"},"source":["# Instruction-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"height":167,"id":"YwB8OLqiflAl"},"outputs":[],"source":["import itertools\n","import jsonlines\n","\n","from datasets import load_dataset\n","from pprint import pprint\n","\n","from llama import BasicModelRunner\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"]},{"cell_type":"markdown","metadata":{"id":"0f7xu-1vV-cS"},"source":["### Setup the LAMINI API KEYÂ¶"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rM3eHwYrV-cT"},"outputs":[],"source":["# LAMINI_API_KEY is saved in `.env` file\n","\n","# !export LAMINI_API_KEY= \"<YOUR-KEY-HERE>\"\n","\n","from dotenv import load_dotenv\n","import os\n","load_dotenv()\n","LAMINI_API_KEY=os.getenv(\"LAMINI_API_KEY\")\n","\n","from llama import LLMEngine\n","\n","llm = LLMEngine(\n","    id=\"marketing\",\n","    config={\n","        \"production\": {\n","            \"key\": LAMINI_API_KEY,\n","        }\n","    },\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"aMlIbp6pV-cT"},"source":["### Load instruction tuned dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"height":52,"id":"alcx_EHNV-cU"},"outputs":[],"source":["instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"height":99,"id":"izlLT-P7V-cU"},"outputs":[],"source":["m = 5\n","print(\"Instruction-tuned dataset:\")\n","top_m = list(itertools.islice(instruction_tuned_dataset, m))\n","for j in top_m:\n","  print(j)"]},{"cell_type":"markdown","metadata":{"id":"uxLzBUSrV-cU"},"source":["### Two prompt templates"]},{"cell_type":"code","execution_count":null,"metadata":{"height":307,"id":"1Xh8HxwEV-cV"},"outputs":[],"source":["prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{instruction}\n","\n","### Input:\n","{input}\n","\n","### Response:\"\"\"\n","\n","prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{instruction}\n","\n","### Response:\"\"\""]},{"cell_type":"markdown","metadata":{"id":"1PO5hQtCV-cV"},"source":["### Hydrate prompts (add data to prompts)"]},{"cell_type":"code","execution_count":null,"metadata":{"height":188,"id":"peRJK52TV-cW"},"outputs":[],"source":["processed_data = []\n","for j in top_m:\n","  if not j[\"input\"]:\n","    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n","  else:\n","    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n","\n","  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"height":31,"id":"4Y4fNvubV-cW"},"outputs":[],"source":["pprint(processed_data[0])"]},{"cell_type":"markdown","metadata":{"id":"AlVWq2XjV-cW"},"source":["### Save data to jsonl"]},{"cell_type":"code","execution_count":null,"metadata":{"height":48,"id":"pvOnT37nV-cX"},"outputs":[],"source":["with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n","    writer.write_all(processed_data)"]},{"cell_type":"markdown","metadata":{"id":"F3JFzFkEV-cX"},"source":["### Compare non-instruction-tuned vs. instruction-tuned models"]},{"cell_type":"code","execution_count":null,"metadata":{"height":65,"id":"bfPeE9vjV-cX"},"outputs":[],"source":["dataset_path_hf = \"lamini/alpaca\"\n","dataset_hf = load_dataset(dataset_path_hf)\n","print(dataset_hf)"]},{"cell_type":"code","execution_count":null,"metadata":{"height":86,"id":"W8yigCBlV-cX"},"outputs":[],"source":["non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n","non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\")\n","print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"height":86,"id":"wp7zOB8hV-cX"},"outputs":[],"source":["instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n","instruct_output = instruct_model(\"Tell me how to train my dog to sit\")\n","print(\"Instruction-tuned output (Llama 2): \", instruct_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"height":86,"id":"yXQQI4xnV-cY"},"outputs":[],"source":["chatgpt = BasicModelRunner(\"chat-gpt\")\n","instruct_output_chatgpt = chatgpt(\"Tell me how to train my dog to sit\")\n","print(\"Instruction-tuned output (ChatGPT): \", instruct_output_chatgpt)"]},{"cell_type":"markdown","metadata":{"id":"HHLb4np_V-cY"},"source":["### Try smaller models"]},{"cell_type":"code","execution_count":null,"metadata":{"height":48,"id":"EwdMkzIaV-cY"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n","model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"]},{"cell_type":"code","execution_count":null,"metadata":{"height":426,"id":"LME-FzydV-cY"},"outputs":[],"source":["def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n","  # Tokenize\n","  input_ids = tokenizer.encode(\n","          text,\n","          return_tensors=\"pt\",\n","          truncation=True,\n","          max_length=max_input_tokens\n","  )\n","\n","  # Generate\n","  device = model.device\n","  generated_tokens_with_prompt = model.generate(\n","    input_ids=input_ids.to(device),\n","    max_length=max_output_tokens\n","  )\n","\n","  # Decode\n","  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n","\n","  # Strip the prompt\n","  generated_text_answer = generated_text_with_prompt[0][len(text):]\n","\n","  return generated_text_answer"]},{"cell_type":"code","execution_count":null,"metadata":{"height":65,"id":"y55LlSA_V-cY"},"outputs":[],"source":["finetuning_dataset_path = \"lamini/lamini_docs\"\n","finetuning_dataset = load_dataset(finetuning_dataset_path)\n","print(finetuning_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"height":82,"id":"OikN03BqV-cY"},"outputs":[],"source":["test_sample = finetuning_dataset[\"test\"][0]\n","print(test_sample)\n","\n","print(inference(test_sample[\"question\"], model, tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"uW0itBxJV-cY"},"source":["### Compare to finetuned small model"]},{"cell_type":"code","execution_count":null,"metadata":{"height":52,"id":"ojF5n98QV-cY"},"outputs":[],"source":["instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"]},{"cell_type":"code","execution_count":null,"metadata":{"height":52,"id":"W2n1OjUvV-cZ"},"outputs":[],"source":["print(inference(test_sample[\"question\"], instruction_model, tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"height":239,"id":"mSJMi8I4Sgrw"},"outputs":[],"source":["# Pssst! If you were curious how to upload your own dataset to Huggingface\n","# Here is how we did it\n","\n","# !pip install huggingface_hub\n","# !huggingface-cli login\n","\n","# import pandas as pd\n","# import datasets\n","# from datasets import Dataset\n","\n","# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))\n","# finetuning_dataset.push_to_hub(dataset_path_hf)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}